{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Luy8avzIXa6g"},"outputs":[],"source":["# import libs\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import VGG19\n","from tensorflow.keras.losses import BinaryCrossentropy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfFrnJfVYAEg"},"outputs":[],"source":["input_shape = (32,32,3)\n","input_shape_disc= (128,128,3)\n","## generator model\n","def residualBlock(input_):\n","  x = keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(input_)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.PReLU(shared_axes=[1, 2])(x)\n","  x = keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  output = keras.layers.Add()([x,input_])\n","  return output\n","\n","def pixelShuffle(scale):\n","  return lambda x: tf.nn.depth_to_space(x,scale)\n","\n","def generator(residual_numbers=16):\n","  inputs = keras.layers.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64,kernel_size=9,strides=1,padding='same')(inputs)\n","  x = keras.layers.PReLU(shared_axes=[1, 2])(x)\n","  skip_connection = x\n","\n","  for _ in range(residual_numbers):\n","   x = residualBlock(x)\n","\n","  x = keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Add()([x,skip_connection])\n","\n","  x = keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(x)\n","  x = keras.layers.Lambda(pixelShuffle(2))(x)\n","  x = keras.layers.PReLU(shared_axes=[1, 2])(x)\n","\n","  x = keras.layers.Conv2D(256,kernel_size=3,strides=1,padding='same')(x)\n","  x = keras.layers.Lambda(pixelShuffle(2))(x)\n","  x = keras.layers.PReLU(shared_axes=[1, 2])(x)\n","\n","  outputs = keras.layers.Conv2D(3,kernel_size=9,strides=1,padding='same',activation='tanh')(x)\n","\n","  model = keras.Model(inputs=inputs,outputs=outputs)\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-v9eD6QYD2y"},"outputs":[],"source":["## discriminator model\n","def block(input_,filter_numbers=128,strides=1):\n","  x = keras.layers.Conv2D(filters=filter_numbers,kernel_size=3,strides=strides,padding='same')(input_)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.LeakyReLU(alpha=0.2)(x)\n","  return x\n","\n","def discriminator():\n","  inputs = keras.layers.Input(shape=input_shape_disc)\n","  x = keras.layers.Conv2D(64,kernel_size=3,strides=1,padding='same')(inputs)\n","  x = keras.layers.LeakyReLU(alpha=0.2)(x)\n","\n","  x = block(x,64,2)\n","  x = block(x,128,1)\n","  x = block(x,128,2)\n","  x = block(x,256,1)\n","  x = block(x,256,2)\n","  x = block(x,512,1)\n","  x = block(x,512,2)\n","\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(1024)(x)\n","\n","  x = keras.layers.LeakyReLU(alpha=0.2)(x)\n","  outputs = keras.layers.Dense(1,activation='sigmoid')(x)\n","\n","  model = keras.Model(inputs=inputs,outputs=outputs)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WqyMpNyLYJh2"},"outputs":[],"source":["## training class\n","class SRGAN(keras.Model):\n","  def __init__(self,discriminator,generator):\n","     super().__init__()\n","     self.discriminator = discriminator\n","     self.generator = generator\n","     self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n","     self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n","     self.binaryCrossentropy = BinaryCrossentropy(from_logits=False)\n","\n","  def compile(self,d_optimizor,g_optimizor):\n","     super().compile()\n","     self.d_optimizor = d_optimizor\n","     self.g_optimizor = g_optimizor\n","\n","  def content_loss(self,hr_image,sr_image):\n","    vgg = VGG19(include_top=False,weights='imagenet')\n","    model = keras.Model(inputs=vgg.input,outputs=vgg.get_layer('block5_conv4').output)\n","\n","    hr_features = model(keras.applications.vgg19.preprocess_input(hr_image))\n","    sr_features = model(keras.applications.vgg19.preprocess_input(sr_image))\n","\n","    content_loss = tf.reduce_mean(tf.square(hr_features - sr_features))\n","    return content_loss\n","\n","  def adversarial_loss(self,disc_output):\n","    return self.binaryCrossentropy(tf.ones_like(disc_output),disc_output)\n","\n","  def discriminator_loss(self,disc_real_output,disc_fake_output):\n","    real_loss = self.binaryCrossentropy(tf.ones_like(disc_real_output),disc_real_output)\n","    fake_loss = self.binaryCrossentropy(tf.zeros_like(disc_fake_output),disc_fake_output)\n","    return real_loss + fake_loss\n","\n","  def generator_loss(self,disc_fake_output,hr_image,sr_image):\n","    content_loss = self.content_loss(hr_image,sr_image)\n","    adversarial_loss = self.adversarial_loss(disc_fake_output)\n","    return content_loss+1e-3*adversarial_loss\n","\n","  #@tf.function\n","  def train_step(self,data):\n","     lr_images,hr_images = data\n","     with tf.GradientTape() as dTape, tf.GradientTape() as gTape:\n","\n","       hr_images = tf.image.resize(hr_images,input_shape_disc[:-1])\n","       sr_images = self.generator(lr_images,training=True)\n","       disc_fake_output = self.discriminator(sr_images,training=True)\n","       disc_real_output = self.discriminator(hr_images,training=True)\n","\n","       generator_loss = self.generator_loss(disc_fake_output,hr_images,sr_images)\n","       disc_loss = self.discriminator_loss(disc_real_output,disc_fake_output)\n","\n","\n","     gen_gradient = gTape.gradient(generator_loss,self.generator.trainable_variables)\n","     disc_gradient = dTape.gradient(disc_loss,self.discriminator.trainable_variables)\n","\n","\n","     self.g_optimizor.apply_gradients(zip(gen_gradient,self.generator.trainable_variables))\n","     self.d_optimizor.apply_gradients(zip(disc_gradient,self.discriminator.trainable_variables))\n","\n","     self.g_loss_tracker.update_state(generator_loss)\n","     self.d_loss_tracker.update_state(disc_loss)\n","     return {\n","         \"d_loss\": self.d_loss_tracker.result(),\n","         \"g_loss\": self.g_loss_tracker.result()\n","     }\n","  @property\n","  def metrics(self):\n","    return [self.g_loss_tracker,self.d_loss_tracker]"]},{"cell_type":"code","source":["batch_size = 32\n","epochs = 50"],"metadata":{"id":"trIOo8Ct81Hk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10562,"status":"ok","timestamp":1727504289021,"user":{"displayName":"Saeid Honardan","userId":"05404479246205043705"},"user_tz":-210},"id":"0ELx2BE8YMa1","outputId":"eab89911-6ad9-4f65-8786-8d8190ae9447"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n","low batch size shape: (32, 32, 32, 3)\n","high batch size shape: (32, 32, 32, 3)\n"]}],"source":["## preprocceing dataset\n","\n","def downscale_image(image,scale=2):\n","  image_size = tf.shape(image)[:2]\n","  new_size = image_size // scale\n","  lr_image = tf.image.resize(image,new_size,method='bicubic')\n","  lr_image = tf.image.resize(lr_image,image_size,method='bicubic')\n","  return lr_image\n","\n","def preprocess_image(image,hr_size=input_shape[:-1]):\n","   hr_image = tf.image.resize(image,hr_size)\n","   hr_image = tf.cast(hr_image,tf.float32)/255.0\n","   lr_image = downscale_image(hr_image)\n","   lr_image = tf.image.resize(lr_image,input_shape[:-1])\n","   return lr_image,hr_image\n","\n","# load cifar10 dataset\n","(x_train,_),(x_test,_) = keras.datasets.cifar10.load_data()\n","train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n","test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n","\n","train_dataset_srgan = train_dataset.map(lambda image: preprocess_image(image))\n","train_dataset_srgan = train_dataset_srgan.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","for lr_image,hr_image in train_dataset_srgan.take(1):\n","  print(\"low batch size shape:\",lr_image.shape)\n","  print(\"high batch size shape:\",hr_image.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":574,"status":"ok","timestamp":1727504289592,"user":{"displayName":"Saeid Honardan","userId":"05404479246205043705"},"user_tz":-210},"id":"HFmrIfN0u1jW","outputId":"1ee194b9-afcc-471c-a5f8-eb70cf5439c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_33               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_34               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_35               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_36               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_42 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_37               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_43 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_38               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_39               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32768\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │      \u001b[38;5;34m33,555,456\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,025\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_33               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_34               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_35               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_36               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_37               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_38               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_39               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32768</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">33,555,456</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,249,281\u001b[0m (145.91 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,249,281</span> (145.91 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,245,569\u001b[0m (145.90 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,245,569</span> (145.90 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n","</pre>\n"]},"metadata":{}}],"source":["#Instantiate Model\n","generator = generator()\n","discriminator = discriminator()\n","srgan = SRGAN(discriminator,generator)\n","srgan.compile(\n","    d_optimizor = keras.optimizers.Adam(learning_rate=0.0003),\n","    g_optimizor = keras.optimizers.Adam(learning_rate=0.0003)\n",")\n","discriminator.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26063,"status":"ok","timestamp":1727504315645,"user":{"displayName":"Saeid Honardan","userId":"05404479246205043705"},"user_tz":-210},"id":"nEn8X4rKlP2V","outputId":"635a0b99-5fa6-472e-cd8b-20b365a8ccc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# callbacks\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","checkpoint_dir = '/content/drive/MyDrive/srgan_checkpoints'\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath = checkpoint_dir+ '/srgan_{epoch:02d}.keras',\n","        monitor='g_loss',\n","        mode='min',\n","        save_best_only=True,\n","        save_weights_only=True\n","    ),\n","    keras.callbacks.EarlyStopping(\n","        monitor='g_loss',\n","        mode='min',\n","        patience=150,\n","        restore_best_weights=True\n","    )\n","]\n","callbackList = keras.callbacks.CallbackList(callbacks)\n","callbackList.set_model(srgan)\n","callbackList.set_params({\n","    'epochs': epochs,\n","    'steps': batch_size,\n","    'verbose':1\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gkKLc1uYGSf","executionInfo":{"status":"ok","timestamp":1727516435220,"user_tz":-210,"elapsed":12119594,"user":{"displayName":"Saeid Honardan","userId":"05404479246205043705"}},"outputId":"90e103f0-93d5-48f9-8e74-a2b37aef01e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, time: 2024-09-28 06:18:34.979133\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","Batch 0, Disc Loss: 1.5423977375030518 , Gen Loss: 0.0012898046988993883, time: 2024-09-28 06:18:53.077561\n","Batch 10, Disc Loss: 2.661508798599243 , Gen Loss: 0.040615107864141464, time: 2024-09-28 06:19:16.652437\n","Batch 20, Disc Loss: 2.2686097621917725 , Gen Loss: 0.03400161862373352, time: 2024-09-28 06:19:40.371244\n","Batch 30, Disc Loss: 3.805115222930908 , Gen Loss: 0.03214787319302559, time: 2024-09-28 06:20:04.018296\n","Batch 40, Disc Loss: 3.7624447345733643 , Gen Loss: 0.026745760813355446, time: 2024-09-28 06:20:27.862250\n","Batch 50, Disc Loss: 3.1052513122558594 , Gen Loss: 0.02433622069656849, time: 2024-09-28 06:20:51.752935\n","Batch 60, Disc Loss: 2.662524700164795 , Gen Loss: 0.022574448958039284, time: 2024-09-28 06:21:15.370733\n","Batch 70, Disc Loss: 2.4852664470672607 , Gen Loss: 0.0216530654579401, time: 2024-09-28 06:21:39.083644\n","Batch 80, Disc Loss: 2.221155881881714 , Gen Loss: 0.021106423810124397, time: 2024-09-28 06:22:03.044740\n","Batch 90, Disc Loss: 1.9915803670883179 , Gen Loss: 0.020597942173480988, time: 2024-09-28 06:22:27.355489\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py:102: UserWarning: You are saving a model that has not yet been built. It might not contain any weights yet. Consider building the model first by calling it on some data.\n","  return saving_lib.save_model(model, filepath)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/50, time: 2024-09-28 06:22:53.485026\n","Batch 0, Disc Loss: 1.802703857421875 , Gen Loss: 0.01972830295562744, time: 2024-09-28 06:22:56.049227\n","Batch 10, Disc Loss: 1.6517943143844604 , Gen Loss: 0.018953239545226097, time: 2024-09-28 06:23:20.754145\n","Batch 20, Disc Loss: 1.5161113739013672 , Gen Loss: 0.018829479813575745, time: 2024-09-28 06:23:44.890361\n","Batch 30, Disc Loss: 1.4110040664672852 , Gen Loss: 0.019493063911795616, time: 2024-09-28 06:24:08.904911\n","Batch 40, Disc Loss: 1.3152350187301636 , Gen Loss: 0.0188888106495142, time: 2024-09-28 06:24:32.909126\n","Batch 50, Disc Loss: 1.231011152267456 , Gen Loss: 0.018261725082993507, time: 2024-09-28 06:24:56.945845\n","Batch 60, Disc Loss: 1.1598132848739624 , Gen Loss: 0.017635570839047432, time: 2024-09-28 06:25:21.210705\n","Batch 70, Disc Loss: 1.0946106910705566 , Gen Loss: 0.01710994727909565, time: 2024-09-28 06:25:45.195347\n","Batch 80, Disc Loss: 1.0358434915542603 , Gen Loss: 0.016650313511490822, time: 2024-09-28 06:26:09.139197\n","Batch 90, Disc Loss: 1.0155912637710571 , Gen Loss: 0.016339832916855812, time: 2024-09-28 06:26:33.322231\n","Epoch 3/50, time: 2024-09-28 06:26:59.261596\n","Batch 0, Disc Loss: 1.1490694284439087 , Gen Loss: 0.017425639554858208, time: 2024-09-28 06:27:01.950125\n","Batch 10, Disc Loss: 1.1704015731811523 , Gen Loss: 0.017593184486031532, time: 2024-09-28 06:27:26.638278\n","Batch 20, Disc Loss: 1.1895081996917725 , Gen Loss: 0.017311111092567444, time: 2024-09-28 06:27:50.871006\n","Batch 30, Disc Loss: 1.189670443534851 , Gen Loss: 0.017008421942591667, time: 2024-09-28 06:28:14.880041\n","Batch 40, Disc Loss: 1.1529468297958374 , Gen Loss: 0.016840852797031403, time: 2024-09-28 06:28:38.862082\n","Batch 50, Disc Loss: 1.1437162160873413 , Gen Loss: 0.01669052056968212, time: 2024-09-28 06:29:02.724868\n","Batch 60, Disc Loss: 1.1168413162231445 , Gen Loss: 0.016755850985646248, time: 2024-09-28 06:29:26.748923\n","Batch 70, Disc Loss: 1.098089337348938 , Gen Loss: 0.016748685389757156, time: 2024-09-28 06:29:50.593087\n","Batch 80, Disc Loss: 1.1015455722808838 , Gen Loss: 0.016683580353856087, time: 2024-09-28 06:30:14.480315\n","Batch 90, Disc Loss: 1.117954134941101 , Gen Loss: 0.016757575795054436, time: 2024-09-28 06:30:38.360818\n","Epoch 4/50, time: 2024-09-28 06:31:04.381373\n","Batch 0, Disc Loss: 1.1312347650527954 , Gen Loss: 0.01666637882590294, time: 2024-09-28 06:31:06.955387\n","Batch 10, Disc Loss: 1.1291038990020752 , Gen Loss: 0.016421908512711525, time: 2024-09-28 06:31:31.351801\n","Batch 20, Disc Loss: 1.1080459356307983 , Gen Loss: 0.01642843708395958, time: 2024-09-28 06:31:55.164999\n","Batch 30, Disc Loss: 1.0804641246795654 , Gen Loss: 0.016311822459101677, time: 2024-09-28 06:32:19.229646\n","Batch 40, Disc Loss: 1.0756568908691406 , Gen Loss: 0.01624307595193386, time: 2024-09-28 06:32:43.235477\n","Batch 50, Disc Loss: 1.0884616374969482 , Gen Loss: 0.016019102185964584, time: 2024-09-28 06:33:07.206406\n","Batch 60, Disc Loss: 1.0774046182632446 , Gen Loss: 0.015839815139770508, time: 2024-09-28 06:33:31.232928\n","Batch 70, Disc Loss: 1.1098377704620361 , Gen Loss: 0.01567208208143711, time: 2024-09-28 06:33:55.435293\n","Batch 80, Disc Loss: 1.15716552734375 , Gen Loss: 0.0157540924847126, time: 2024-09-28 06:34:19.350693\n","Batch 90, Disc Loss: 1.1533610820770264 , Gen Loss: 0.015687530860304832, time: 2024-09-28 06:34:43.388607\n","Epoch 5/50, time: 2024-09-28 06:35:09.652956\n","Batch 0, Disc Loss: 1.1647297143936157 , Gen Loss: 0.015502868220210075, time: 2024-09-28 06:35:12.184375\n","Batch 10, Disc Loss: 1.1523783206939697 , Gen Loss: 0.01535051129758358, time: 2024-09-28 06:35:36.593962\n","Batch 20, Disc Loss: 1.137430191040039 , Gen Loss: 0.015204821713268757, time: 2024-09-28 06:36:00.514070\n","Batch 30, Disc Loss: 1.1461167335510254 , Gen Loss: 0.0151114072650671, time: 2024-09-28 06:36:24.329025\n","Batch 40, Disc Loss: 1.2038805484771729 , Gen Loss: 0.014971879310905933, time: 2024-09-28 06:36:48.381292\n","Batch 50, Disc Loss: 1.2073780298233032 , Gen Loss: 0.014802645891904831, time: 2024-09-28 06:37:12.271624\n","Batch 60, Disc Loss: 1.2242919206619263 , Gen Loss: 0.01460046973079443, time: 2024-09-28 06:37:36.121377\n","Batch 70, Disc Loss: 1.2595040798187256 , Gen Loss: 0.014447168447077274, time: 2024-09-28 06:38:00.162729\n","Batch 80, Disc Loss: 1.3245586156845093 , Gen Loss: 0.014282775111496449, time: 2024-09-28 06:38:24.043871\n","Batch 90, Disc Loss: 1.3344227075576782 , Gen Loss: 0.014111139811575413, time: 2024-09-28 06:38:47.938095\n","Epoch 6/50, time: 2024-09-28 06:39:13.680316\n","Batch 0, Disc Loss: 1.3366771936416626 , Gen Loss: 0.01393737830221653, time: 2024-09-28 06:39:16.236528\n","Batch 10, Disc Loss: 1.3340431451797485 , Gen Loss: 0.013899211771786213, time: 2024-09-28 06:39:40.601716\n","Batch 20, Disc Loss: 1.3349812030792236 , Gen Loss: 0.01377615425735712, time: 2024-09-28 06:40:04.255417\n","Batch 30, Disc Loss: 1.337229609489441 , Gen Loss: 0.01365169882774353, time: 2024-09-28 06:40:27.942176\n","Batch 40, Disc Loss: 1.3319669961929321 , Gen Loss: 0.013658203184604645, time: 2024-09-28 06:40:51.812934\n","Batch 50, Disc Loss: 1.3423010110855103 , Gen Loss: 0.013730802573263645, time: 2024-09-28 06:41:15.619184\n","Batch 60, Disc Loss: 1.3438814878463745 , Gen Loss: 0.013702471740543842, time: 2024-09-28 06:41:39.369953\n","Batch 70, Disc Loss: 1.3279858827590942 , Gen Loss: 0.013598955236375332, time: 2024-09-28 06:42:03.209928\n","Batch 80, Disc Loss: 1.3305964469909668 , Gen Loss: 0.01353323832154274, time: 2024-09-28 06:42:27.489254\n","Batch 90, Disc Loss: 1.320981502532959 , Gen Loss: 0.013409068807959557, time: 2024-09-28 06:42:51.461131\n","Epoch 7/50, time: 2024-09-28 06:43:17.448406\n","Batch 0, Disc Loss: 1.3080781698226929 , Gen Loss: 0.013256155885756016, time: 2024-09-28 06:43:20.015365\n","Batch 10, Disc Loss: 1.2914972305297852 , Gen Loss: 0.013122073374688625, time: 2024-09-28 06:43:44.362547\n","Batch 20, Disc Loss: 1.2750117778778076 , Gen Loss: 0.013002525083720684, time: 2024-09-28 06:44:08.182174\n","Batch 30, Disc Loss: 1.2606927156448364 , Gen Loss: 0.012884290888905525, time: 2024-09-28 06:44:32.013907\n","Batch 40, Disc Loss: 1.2471683025360107 , Gen Loss: 0.012767508625984192, time: 2024-09-28 06:44:55.792499\n","Batch 50, Disc Loss: 1.2355780601501465 , Gen Loss: 0.012647341936826706, time: 2024-09-28 06:45:19.715765\n","Batch 60, Disc Loss: 1.2263128757476807 , Gen Loss: 0.01252826489508152, time: 2024-09-28 06:45:43.505009\n","Batch 70, Disc Loss: 1.2213853597640991 , Gen Loss: 0.012404793873429298, time: 2024-09-28 06:46:07.322988\n","Batch 80, Disc Loss: 1.2233963012695312 , Gen Loss: 0.012284649536013603, time: 2024-09-28 06:46:31.420221\n","Batch 90, Disc Loss: 1.2412303686141968 , Gen Loss: 0.012203462421894073, time: 2024-09-28 06:46:55.466761\n","Epoch 8/50, time: 2024-09-28 06:47:21.334615\n","Batch 0, Disc Loss: 1.255857229232788 , Gen Loss: 0.01213130448013544, time: 2024-09-28 06:47:23.886530\n","Batch 10, Disc Loss: 1.261351227760315 , Gen Loss: 0.012054912745952606, time: 2024-09-28 06:47:48.208049\n","Batch 20, Disc Loss: 1.2543543577194214 , Gen Loss: 0.011950826272368431, time: 2024-09-28 06:48:12.204663\n","Batch 30, Disc Loss: 1.2497144937515259 , Gen Loss: 0.011834834702312946, time: 2024-09-28 06:48:35.894192\n","Batch 40, Disc Loss: 1.2407128810882568 , Gen Loss: 0.01171867549419403, time: 2024-09-28 06:48:59.708876\n","Batch 50, Disc Loss: 1.2287636995315552 , Gen Loss: 0.011612965725362301, time: 2024-09-28 06:49:23.621710\n","Batch 60, Disc Loss: 1.2246205806732178 , Gen Loss: 0.01150188222527504, time: 2024-09-28 06:49:47.355081\n","Batch 70, Disc Loss: 1.2187039852142334 , Gen Loss: 0.011391639709472656, time: 2024-09-28 06:50:11.205310\n","Batch 80, Disc Loss: 1.2104132175445557 , Gen Loss: 0.011301856487989426, time: 2024-09-28 06:50:35.158763\n","Batch 90, Disc Loss: 1.2016186714172363 , Gen Loss: 0.011232443153858185, time: 2024-09-28 06:50:58.947819\n","Epoch 9/50, time: 2024-09-28 06:51:24.739361\n","Batch 0, Disc Loss: 1.1987642049789429 , Gen Loss: 0.01114925742149353, time: 2024-09-28 06:51:27.295251\n","Batch 10, Disc Loss: 1.1972543001174927 , Gen Loss: 0.011053268797695637, time: 2024-09-28 06:51:51.522281\n","Batch 20, Disc Loss: 1.1895750761032104 , Gen Loss: 0.010954836383461952, time: 2024-09-28 06:52:15.551200\n","Batch 30, Disc Loss: 1.1885157823562622 , Gen Loss: 0.010864099487662315, time: 2024-09-28 06:52:39.331194\n","Batch 40, Disc Loss: 1.181039810180664 , Gen Loss: 0.010800294578075409, time: 2024-09-28 06:53:03.245126\n","Batch 50, Disc Loss: 1.1906770467758179 , Gen Loss: 0.010742894373834133, time: 2024-09-28 06:53:27.238321\n","Batch 60, Disc Loss: 1.1876742839813232 , Gen Loss: 0.010658885352313519, time: 2024-09-28 06:53:51.149167\n","Batch 70, Disc Loss: 1.1849572658538818 , Gen Loss: 0.010564608499407768, time: 2024-09-28 06:54:14.987250\n","Batch 80, Disc Loss: 1.1790872812271118 , Gen Loss: 0.010476105846464634, time: 2024-09-28 06:54:38.723724\n","Batch 90, Disc Loss: 1.1765540838241577 , Gen Loss: 0.010386539623141289, time: 2024-09-28 06:55:02.641668\n","Epoch 10/50, time: 2024-09-28 06:55:28.305075\n","Batch 0, Disc Loss: 1.1768447160720825 , Gen Loss: 0.010312017053365707, time: 2024-09-28 06:55:30.823509\n","Batch 10, Disc Loss: 1.1747678518295288 , Gen Loss: 0.01023045089095831, time: 2024-09-28 06:55:55.031169\n","Batch 20, Disc Loss: 1.1791435480117798 , Gen Loss: 0.01015673391520977, time: 2024-09-28 06:56:18.828495\n","Batch 30, Disc Loss: 1.1796772480010986 , Gen Loss: 0.01008258480578661, time: 2024-09-28 06:56:42.321475\n","Batch 40, Disc Loss: 1.1811226606369019 , Gen Loss: 0.010024948976933956, time: 2024-09-28 06:57:05.889933\n","Batch 50, Disc Loss: 1.1778594255447388 , Gen Loss: 0.009961518459022045, time: 2024-09-28 06:57:29.527861\n","Batch 60, Disc Loss: 1.1719892024993896 , Gen Loss: 0.009932054206728935, time: 2024-09-28 06:57:53.234249\n","Batch 70, Disc Loss: 1.1681650876998901 , Gen Loss: 0.009885044768452644, time: 2024-09-28 06:58:16.644105\n","Batch 80, Disc Loss: 1.1684657335281372 , Gen Loss: 0.009859103709459305, time: 2024-09-28 06:58:40.130528\n","Batch 90, Disc Loss: 1.1708601713180542 , Gen Loss: 0.009800671599805355, time: 2024-09-28 06:59:03.802406\n","Epoch 11/50, time: 2024-09-28 06:59:29.310260\n","Batch 0, Disc Loss: 1.167905569076538 , Gen Loss: 0.009747987613081932, time: 2024-09-28 06:59:31.822913\n","Batch 10, Disc Loss: 1.168412208557129 , Gen Loss: 0.00968395359814167, time: 2024-09-28 06:59:55.870447\n","Batch 20, Disc Loss: 1.172235369682312 , Gen Loss: 0.009608813561499119, time: 2024-09-28 07:00:19.469005\n","Batch 30, Disc Loss: 1.1642996072769165 , Gen Loss: 0.009552016854286194, time: 2024-09-28 07:00:43.194555\n","Batch 40, Disc Loss: 1.1636066436767578 , Gen Loss: 0.009491236880421638, time: 2024-09-28 07:01:06.747191\n","Batch 50, Disc Loss: 1.1667687892913818 , Gen Loss: 0.009427908807992935, time: 2024-09-28 07:01:30.229084\n","Batch 60, Disc Loss: 1.1647261381149292 , Gen Loss: 0.009373949840664864, time: 2024-09-28 07:01:53.942016\n","Batch 70, Disc Loss: 1.168179988861084 , Gen Loss: 0.009310080669820309, time: 2024-09-28 07:02:17.526530\n","Batch 80, Disc Loss: 1.1693949699401855 , Gen Loss: 0.009246348403394222, time: 2024-09-28 07:02:41.317617\n","Batch 90, Disc Loss: 1.1742244958877563 , Gen Loss: 0.009180533699691296, time: 2024-09-28 07:03:05.136552\n","Epoch 12/50, time: 2024-09-28 07:03:31.245438\n","Batch 0, Disc Loss: 1.1694835424423218 , Gen Loss: 0.009126190096139908, time: 2024-09-28 07:03:33.797667\n","Batch 10, Disc Loss: 1.1677303314208984 , Gen Loss: 0.009068804793059826, time: 2024-09-28 07:03:58.036797\n","Batch 20, Disc Loss: 1.165182113647461 , Gen Loss: 0.009019973687827587, time: 2024-09-28 07:04:21.810054\n","Batch 30, Disc Loss: 1.1621779203414917 , Gen Loss: 0.008970988914370537, time: 2024-09-28 07:04:45.711637\n","Batch 40, Disc Loss: 1.159331202507019 , Gen Loss: 0.00891931913793087, time: 2024-09-28 07:05:09.328230\n","Batch 50, Disc Loss: 1.1534984111785889 , Gen Loss: 0.008882635273039341, time: 2024-09-28 07:05:32.964200\n","Batch 60, Disc Loss: 1.1462006568908691 , Gen Loss: 0.008836033754050732, time: 2024-09-28 07:05:56.670325\n","Batch 70, Disc Loss: 1.140689492225647 , Gen Loss: 0.008789139799773693, time: 2024-09-28 07:06:20.646676\n","Batch 80, Disc Loss: 1.1379621028900146 , Gen Loss: 0.00874186772853136, time: 2024-09-28 07:06:44.357198\n","Batch 90, Disc Loss: 1.1366207599639893 , Gen Loss: 0.008700164034962654, time: 2024-09-28 07:07:08.042735\n","Epoch 13/50, time: 2024-09-28 07:07:34.039042\n","Batch 0, Disc Loss: 1.1349222660064697 , Gen Loss: 0.008661579340696335, time: 2024-09-28 07:07:36.606907\n","Batch 10, Disc Loss: 1.1361918449401855 , Gen Loss: 0.00861641950905323, time: 2024-09-28 07:08:00.856798\n","Batch 20, Disc Loss: 1.1310906410217285 , Gen Loss: 0.0085780443623662, time: 2024-09-28 07:08:24.678446\n","Batch 30, Disc Loss: 1.126573085784912 , Gen Loss: 0.008542210794985294, time: 2024-09-28 07:08:48.468007\n","Batch 40, Disc Loss: 1.124513864517212 , Gen Loss: 0.008505362085998058, time: 2024-09-28 07:09:12.239247\n","Batch 50, Disc Loss: 1.123671293258667 , Gen Loss: 0.008465567603707314, time: 2024-09-28 07:09:35.899150\n","Batch 60, Disc Loss: 1.1231378316879272 , Gen Loss: 0.008418642915785313, time: 2024-09-28 07:09:59.534534\n","Batch 70, Disc Loss: 1.1220980882644653 , Gen Loss: 0.008372467942535877, time: 2024-09-28 07:10:23.457988\n","Batch 80, Disc Loss: 1.1169592142105103 , Gen Loss: 0.008335893042385578, time: 2024-09-28 07:10:47.175588\n","Batch 90, Disc Loss: 1.111426591873169 , Gen Loss: 0.008299578912556171, time: 2024-09-28 07:11:10.772974\n","Epoch 14/50, time: 2024-09-28 07:11:36.414121\n","Batch 0, Disc Loss: 1.109524130821228 , Gen Loss: 0.008271700702607632, time: 2024-09-28 07:11:38.954276\n","Batch 10, Disc Loss: 1.1124401092529297 , Gen Loss: 0.008239159360527992, time: 2024-09-28 07:12:03.085688\n","Batch 20, Disc Loss: 1.1114388704299927 , Gen Loss: 0.008202099241316319, time: 2024-09-28 07:12:26.722859\n","Batch 30, Disc Loss: 1.111191987991333 , Gen Loss: 0.008168320171535015, time: 2024-09-28 07:12:50.338457\n","Batch 40, Disc Loss: 1.114978551864624 , Gen Loss: 0.00812698807567358, time: 2024-09-28 07:13:14.231615\n","Batch 50, Disc Loss: 1.1126070022583008 , Gen Loss: 0.008091545663774014, time: 2024-09-28 07:13:37.951064\n","Batch 60, Disc Loss: 1.105857014656067 , Gen Loss: 0.008069119416177273, time: 2024-09-28 07:14:01.525667\n","Batch 70, Disc Loss: 1.099447250366211 , Gen Loss: 0.008040562272071838, time: 2024-09-28 07:14:25.322572\n","Batch 80, Disc Loss: 1.0997045040130615 , Gen Loss: 0.007999381050467491, time: 2024-09-28 07:14:48.945278\n","Batch 90, Disc Loss: 1.0959361791610718 , Gen Loss: 0.007963449694216251, time: 2024-09-28 07:15:12.624113\n","Epoch 15/50, time: 2024-09-28 07:15:38.313096\n","Batch 0, Disc Loss: 1.0898445844650269 , Gen Loss: 0.007945481687784195, time: 2024-09-28 07:15:40.858694\n","Batch 10, Disc Loss: 1.0879021883010864 , Gen Loss: 0.007925573736429214, time: 2024-09-28 07:16:05.278032\n","Batch 20, Disc Loss: 1.0857911109924316 , Gen Loss: 0.007900203578174114, time: 2024-09-28 07:16:29.030088\n","Batch 30, Disc Loss: 1.0853638648986816 , Gen Loss: 0.00787210464477539, time: 2024-09-28 07:16:52.713588\n","Batch 40, Disc Loss: 1.0842162370681763 , Gen Loss: 0.007841003127396107, time: 2024-09-28 07:17:16.604637\n","Batch 50, Disc Loss: 1.0832358598709106 , Gen Loss: 0.007808568421751261, time: 2024-09-28 07:17:40.366966\n","Batch 60, Disc Loss: 1.0817594528198242 , Gen Loss: 0.007773666176944971, time: 2024-09-28 07:18:04.095304\n","Batch 70, Disc Loss: 1.081364631652832 , Gen Loss: 0.007741969544440508, time: 2024-09-28 07:18:27.877710\n","Batch 80, Disc Loss: 1.0919703245162964 , Gen Loss: 0.007704843766987324, time: 2024-09-28 07:18:51.734301\n","Batch 90, Disc Loss: 1.0936957597732544 , Gen Loss: 0.0076754409819841385, time: 2024-09-28 07:19:15.437490\n","Epoch 16/50, time: 2024-09-28 07:19:41.010950\n","Batch 0, Disc Loss: 1.0898447036743164 , Gen Loss: 0.007646860554814339, time: 2024-09-28 07:19:43.527060\n","Batch 10, Disc Loss: 1.0857882499694824 , Gen Loss: 0.0076171462424099445, time: 2024-09-28 07:20:07.735427\n","Batch 20, Disc Loss: 1.084736943244934 , Gen Loss: 0.007584112696349621, time: 2024-09-28 07:20:31.277869\n","Batch 30, Disc Loss: 1.0797061920166016 , Gen Loss: 0.007562908343970776, time: 2024-09-28 07:20:54.746326\n","Batch 40, Disc Loss: 1.0788698196411133 , Gen Loss: 0.007532911375164986, time: 2024-09-28 07:21:18.287360\n","Batch 50, Disc Loss: 1.0743416547775269 , Gen Loss: 0.00751123670488596, time: 2024-09-28 07:21:41.888727\n","Batch 60, Disc Loss: 1.0714235305786133 , Gen Loss: 0.007485872134566307, time: 2024-09-28 07:22:05.350357\n","Batch 70, Disc Loss: 1.0736030340194702 , Gen Loss: 0.007462011184543371, time: 2024-09-28 07:22:28.959761\n","Batch 80, Disc Loss: 1.074296236038208 , Gen Loss: 0.007433058228343725, time: 2024-09-28 07:22:52.777220\n","Batch 90, Disc Loss: 1.0736432075500488 , Gen Loss: 0.007402862422168255, time: 2024-09-28 07:23:16.448200\n","Epoch 17/50, time: 2024-09-28 07:23:42.059316\n","Batch 0, Disc Loss: 1.075659990310669 , Gen Loss: 0.007378559559583664, time: 2024-09-28 07:23:44.577331\n","Batch 10, Disc Loss: 1.0755633115768433 , Gen Loss: 0.007351412903517485, time: 2024-09-28 07:24:08.760972\n","Batch 20, Disc Loss: 1.0740522146224976 , Gen Loss: 0.007329081650823355, time: 2024-09-28 07:24:32.559263\n","Batch 30, Disc Loss: 1.0756008625030518 , Gen Loss: 0.007307169958949089, time: 2024-09-28 07:24:56.255502\n","Batch 40, Disc Loss: 1.0722852945327759 , Gen Loss: 0.0072868382558226585, time: 2024-09-28 07:25:19.924003\n","Batch 50, Disc Loss: 1.0702357292175293 , Gen Loss: 0.007268402725458145, time: 2024-09-28 07:25:43.716990\n","Batch 60, Disc Loss: 1.0661503076553345 , Gen Loss: 0.007254696451127529, time: 2024-09-28 07:26:07.383490\n","Batch 70, Disc Loss: 1.0633544921875 , Gen Loss: 0.007232463452965021, time: 2024-09-28 07:26:31.010286\n","Batch 80, Disc Loss: 1.0625460147857666 , Gen Loss: 0.007211446762084961, time: 2024-09-28 07:26:54.627976\n","Batch 90, Disc Loss: 1.0596240758895874 , Gen Loss: 0.007191602606326342, time: 2024-09-28 07:27:18.483654\n","Epoch 18/50, time: 2024-09-28 07:27:43.854102\n","Batch 0, Disc Loss: 1.059924602508545 , Gen Loss: 0.007169382646679878, time: 2024-09-28 07:27:46.381966\n","Batch 10, Disc Loss: 1.0599560737609863 , Gen Loss: 0.007144562900066376, time: 2024-09-28 07:28:10.208880\n","Batch 20, Disc Loss: 1.057692527770996 , Gen Loss: 0.0071188779547810555, time: 2024-09-28 07:28:34.005764\n","Batch 30, Disc Loss: 1.0549660921096802 , Gen Loss: 0.007097641471773386, time: 2024-09-28 07:28:57.622610\n","Batch 40, Disc Loss: 1.0562655925750732 , Gen Loss: 0.007075465749949217, time: 2024-09-28 07:29:21.248374\n","Batch 50, Disc Loss: 1.057185411453247 , Gen Loss: 0.007050863932818174, time: 2024-09-28 07:29:44.872166\n","Batch 60, Disc Loss: 1.0532078742980957 , Gen Loss: 0.007032036315649748, time: 2024-09-28 07:30:08.590631\n","Batch 70, Disc Loss: 1.052433967590332 , Gen Loss: 0.007011863868683577, time: 2024-09-28 07:30:32.144690\n","Batch 80, Disc Loss: 1.0551117658615112 , Gen Loss: 0.006991748232394457, time: 2024-09-28 07:30:55.786038\n","Batch 90, Disc Loss: 1.0565766096115112 , Gen Loss: 0.006980035919696093, time: 2024-09-28 07:31:19.489318\n","Epoch 19/50, time: 2024-09-28 07:31:45.187881\n","Batch 0, Disc Loss: 1.0532286167144775 , Gen Loss: 0.006961516570299864, time: 2024-09-28 07:31:47.686459\n","Batch 10, Disc Loss: 1.0538114309310913 , Gen Loss: 0.006938534323126078, time: 2024-09-28 07:32:11.551610\n","Batch 20, Disc Loss: 1.050774335861206 , Gen Loss: 0.006926426198333502, time: 2024-09-28 07:32:35.493036\n","Batch 30, Disc Loss: 1.0512161254882812 , Gen Loss: 0.006906359922140837, time: 2024-09-28 07:32:59.020736\n","Batch 40, Disc Loss: 1.0558364391326904 , Gen Loss: 0.006884124595671892, time: 2024-09-28 07:33:22.597191\n","Batch 50, Disc Loss: 1.0523645877838135 , Gen Loss: 0.006864754483103752, time: 2024-09-28 07:33:46.328233\n","Batch 60, Disc Loss: 1.0515490770339966 , Gen Loss: 0.006845391821116209, time: 2024-09-28 07:34:10.067033\n","Batch 70, Disc Loss: 1.0524837970733643 , Gen Loss: 0.006823353469371796, time: 2024-09-28 07:34:33.683611\n","Batch 80, Disc Loss: 1.0492331981658936 , Gen Loss: 0.006806013640016317, time: 2024-09-28 07:34:57.270424\n","Batch 90, Disc Loss: 1.045345425605774 , Gen Loss: 0.0067967879585921764, time: 2024-09-28 07:35:21.129327\n","Epoch 20/50, time: 2024-09-28 07:35:46.659350\n","Batch 0, Disc Loss: 1.046958327293396 , Gen Loss: 0.006777176633477211, time: 2024-09-28 07:35:49.183535\n","Batch 10, Disc Loss: 1.0495798587799072 , Gen Loss: 0.006753891706466675, time: 2024-09-28 07:36:13.322056\n","Batch 20, Disc Loss: 1.0515285730361938 , Gen Loss: 0.006730556022375822, time: 2024-09-28 07:36:37.037048\n","Batch 30, Disc Loss: 1.0509873628616333 , Gen Loss: 0.006707386113703251, time: 2024-09-28 07:37:00.860388\n","Batch 40, Disc Loss: 1.0503792762756348 , Gen Loss: 0.006685873959213495, time: 2024-09-28 07:37:24.429514\n","Batch 50, Disc Loss: 1.050631046295166 , Gen Loss: 0.00666264072060585, time: 2024-09-28 07:37:47.972718\n","Batch 60, Disc Loss: 1.047821283340454 , Gen Loss: 0.006643173284828663, time: 2024-09-28 07:38:11.715288\n","Batch 70, Disc Loss: 1.0453351736068726 , Gen Loss: 0.006622991990298033, time: 2024-09-28 07:38:35.288398\n","Batch 80, Disc Loss: 1.0460381507873535 , Gen Loss: 0.006600001826882362, time: 2024-09-28 07:38:58.905286\n","Batch 90, Disc Loss: 1.0440094470977783 , Gen Loss: 0.00658100750297308, time: 2024-09-28 07:39:22.439709\n","Epoch 21/50, time: 2024-09-28 07:39:48.244248\n","Batch 0, Disc Loss: 1.0434495210647583 , Gen Loss: 0.006560278590768576, time: 2024-09-28 07:39:50.756610\n","Batch 10, Disc Loss: 1.0440713167190552 , Gen Loss: 0.006537298671901226, time: 2024-09-28 07:40:14.752974\n","Batch 20, Disc Loss: 1.0444515943527222 , Gen Loss: 0.006519109010696411, time: 2024-09-28 07:40:38.407123\n","Batch 30, Disc Loss: 1.0475374460220337 , Gen Loss: 0.0064971898682415485, time: 2024-09-28 07:41:02.331676\n","Batch 40, Disc Loss: 1.0498796701431274 , Gen Loss: 0.006474701222032309, time: 2024-09-28 07:41:25.896603\n","Batch 50, Disc Loss: 1.050524115562439 , Gen Loss: 0.006452128756791353, time: 2024-09-28 07:41:49.533399\n","Batch 60, Disc Loss: 1.0501055717468262 , Gen Loss: 0.00642984127625823, time: 2024-09-28 07:42:13.180183\n","Batch 70, Disc Loss: 1.048174262046814 , Gen Loss: 0.006410015281289816, time: 2024-09-28 07:42:37.062355\n","Batch 80, Disc Loss: 1.0478335618972778 , Gen Loss: 0.006390759721398354, time: 2024-09-28 07:43:00.753638\n","Batch 90, Disc Loss: 1.0468662977218628 , Gen Loss: 0.0063726999796926975, time: 2024-09-28 07:43:24.332664\n","Epoch 22/50, time: 2024-09-28 07:43:50.352949\n","Batch 0, Disc Loss: 1.0467216968536377 , Gen Loss: 0.006354061421006918, time: 2024-09-28 07:43:52.995929\n","Batch 10, Disc Loss: 1.0463204383850098 , Gen Loss: 0.0063355453312397, time: 2024-09-28 07:44:17.107656\n","Batch 20, Disc Loss: 1.0426591634750366 , Gen Loss: 0.006324366200715303, time: 2024-09-28 07:44:40.916867\n","Batch 30, Disc Loss: 1.039242148399353 , Gen Loss: 0.006315016653388739, time: 2024-09-28 07:45:04.608491\n","Batch 40, Disc Loss: 1.037969708442688 , Gen Loss: 0.006309189833700657, time: 2024-09-28 07:45:28.500757\n","Batch 50, Disc Loss: 1.0411440134048462 , Gen Loss: 0.006290967110544443, time: 2024-09-28 07:45:52.305785\n","Batch 60, Disc Loss: 1.0383374691009521 , Gen Loss: 0.006273687817156315, time: 2024-09-28 07:46:16.073005\n","Batch 70, Disc Loss: 1.036150574684143 , Gen Loss: 0.006256880238652229, time: 2024-09-28 07:46:39.985487\n","Batch 80, Disc Loss: 1.037814736366272 , Gen Loss: 0.006235996726900339, time: 2024-09-28 07:47:03.717171\n","Batch 90, Disc Loss: 1.038082242012024 , Gen Loss: 0.006216603796929121, time: 2024-09-28 07:47:27.497387\n","Epoch 23/50, time: 2024-09-28 07:47:53.231949\n","Batch 0, Disc Loss: 1.0360387563705444 , Gen Loss: 0.006199793424457312, time: 2024-09-28 07:47:56.019990\n","Batch 10, Disc Loss: 1.0361491441726685 , Gen Loss: 0.006180137395858765, time: 2024-09-28 07:48:19.980859\n","Batch 20, Disc Loss: 1.0335792303085327 , Gen Loss: 0.006163869518786669, time: 2024-09-28 07:48:43.699532\n","Batch 30, Disc Loss: 1.0328477621078491 , Gen Loss: 0.006149942521005869, time: 2024-09-28 07:49:07.349338\n","Batch 40, Disc Loss: 1.0328844785690308 , Gen Loss: 0.006135203409940004, time: 2024-09-28 07:49:31.043406\n","Batch 50, Disc Loss: 1.0316283702850342 , Gen Loss: 0.0061220391653478146, time: 2024-09-28 07:49:54.529146\n","Batch 60, Disc Loss: 1.0290664434432983 , Gen Loss: 0.006108582019805908, time: 2024-09-28 07:50:18.080720\n","Batch 70, Disc Loss: 1.0298278331756592 , Gen Loss: 0.006090833339840174, time: 2024-09-28 07:50:41.717521\n","Batch 80, Disc Loss: 1.029943585395813 , Gen Loss: 0.00607430562376976, time: 2024-09-28 07:51:05.232366\n","Batch 90, Disc Loss: 1.0295137166976929 , Gen Loss: 0.006058559287339449, time: 2024-09-28 07:51:28.739727\n","Epoch 24/50, time: 2024-09-28 07:51:54.201174\n","Batch 0, Disc Loss: 1.0283536911010742 , Gen Loss: 0.006042533554136753, time: 2024-09-28 07:51:56.684170\n","Batch 10, Disc Loss: 1.026160717010498 , Gen Loss: 0.006028102245181799, time: 2024-09-28 07:52:20.826675\n","Batch 20, Disc Loss: 1.0290881395339966 , Gen Loss: 0.006010096985846758, time: 2024-09-28 07:52:44.477699\n","Batch 30, Disc Loss: 1.029740810394287 , Gen Loss: 0.005993036553263664, time: 2024-09-28 07:53:08.166373\n","Batch 40, Disc Loss: 1.0281767845153809 , Gen Loss: 0.005978055763989687, time: 2024-09-28 07:53:32.069872\n","Batch 50, Disc Loss: 1.0257608890533447 , Gen Loss: 0.005966069642454386, time: 2024-09-28 07:53:55.716461\n","Batch 60, Disc Loss: 1.0245479345321655 , Gen Loss: 0.005953493993729353, time: 2024-09-28 07:54:19.509074\n","Batch 70, Disc Loss: 1.02388334274292 , Gen Loss: 0.005941473878920078, time: 2024-09-28 07:54:43.313708\n","Batch 80, Disc Loss: 1.023384690284729 , Gen Loss: 0.005926451180130243, time: 2024-09-28 07:55:06.885798\n","Batch 90, Disc Loss: 1.020227074623108 , Gen Loss: 0.0059167672879993916, time: 2024-09-28 07:55:30.591323\n","Epoch 25/50, time: 2024-09-28 07:55:56.370717\n","Batch 0, Disc Loss: 1.0209085941314697 , Gen Loss: 0.005910370498895645, time: 2024-09-28 07:55:58.891702\n","Batch 10, Disc Loss: 1.0225319862365723 , Gen Loss: 0.005899632349610329, time: 2024-09-28 07:56:23.197932\n","Batch 20, Disc Loss: 1.022948145866394 , Gen Loss: 0.005881604738533497, time: 2024-09-28 07:56:46.779691\n","Batch 30, Disc Loss: 1.0216877460479736 , Gen Loss: 0.005866584368050098, time: 2024-09-28 07:57:10.307973\n","Batch 40, Disc Loss: 1.0215380191802979 , Gen Loss: 0.0058504617772996426, time: 2024-09-28 07:57:34.025197\n","Batch 50, Disc Loss: 1.0201029777526855 , Gen Loss: 0.005835795775055885, time: 2024-09-28 07:57:57.575227\n","Batch 60, Disc Loss: 1.0183494091033936 , Gen Loss: 0.005822942592203617, time: 2024-09-28 07:58:21.162700\n","Batch 70, Disc Loss: 1.0166367292404175 , Gen Loss: 0.005810899659991264, time: 2024-09-28 07:58:44.715867\n","Batch 80, Disc Loss: 1.0144222974777222 , Gen Loss: 0.005803542211651802, time: 2024-09-28 07:59:08.446219\n","Batch 90, Disc Loss: 1.0137094259262085 , Gen Loss: 0.005791293457150459, time: 2024-09-28 07:59:31.972142\n","Epoch 26/50, time: 2024-09-28 07:59:57.373152\n","Batch 0, Disc Loss: 1.0131028890609741 , Gen Loss: 0.0057809557765722275, time: 2024-09-28 07:59:59.895826\n","Batch 10, Disc Loss: 1.0122950077056885 , Gen Loss: 0.005767928436398506, time: 2024-09-28 08:00:24.193328\n","Batch 20, Disc Loss: 1.0115572214126587 , Gen Loss: 0.005756907165050507, time: 2024-09-28 08:00:47.767325\n","Batch 30, Disc Loss: 1.010994791984558 , Gen Loss: 0.005744652356952429, time: 2024-09-28 08:01:11.255909\n","Batch 40, Disc Loss: 1.008419156074524 , Gen Loss: 0.005734454374760389, time: 2024-09-28 08:01:34.776693\n","Batch 50, Disc Loss: 1.006489872932434 , Gen Loss: 0.005723104812204838, time: 2024-09-28 08:01:58.412948\n","Batch 60, Disc Loss: 1.0071020126342773 , Gen Loss: 0.005710273515433073, time: 2024-09-28 08:02:21.960713\n","Batch 70, Disc Loss: 1.0055922269821167 , Gen Loss: 0.0056982324458658695, time: 2024-09-28 08:02:45.582667\n","Batch 80, Disc Loss: 1.004992961883545 , Gen Loss: 0.00568612664937973, time: 2024-09-28 08:03:09.381040\n","Batch 90, Disc Loss: 1.0053790807724 , Gen Loss: 0.005672947503626347, time: 2024-09-28 08:03:33.026474\n","Epoch 27/50, time: 2024-09-28 08:03:58.882399\n","Batch 0, Disc Loss: 1.0046377182006836 , Gen Loss: 0.005665745586156845, time: 2024-09-28 08:04:01.395993\n","Batch 10, Disc Loss: 1.0010722875595093 , Gen Loss: 0.0056715901009738445, time: 2024-09-28 08:04:25.685589\n","Batch 20, Disc Loss: 0.9974573254585266 , Gen Loss: 0.005669581238180399, time: 2024-09-28 08:04:49.616083\n","Batch 30, Disc Loss: 0.9945467114448547 , Gen Loss: 0.0056672715581953526, time: 2024-09-28 08:05:13.285610\n","Batch 40, Disc Loss: 0.9960137009620667 , Gen Loss: 0.005658965092152357, time: 2024-09-28 08:05:37.031895\n","Batch 50, Disc Loss: 0.9955424666404724 , Gen Loss: 0.005647935438901186, time: 2024-09-28 08:06:00.913881\n","Batch 60, Disc Loss: 0.9951958060264587 , Gen Loss: 0.005635038483887911, time: 2024-09-28 08:06:24.518926\n","Batch 70, Disc Loss: 0.9940268397331238 , Gen Loss: 0.005623668897897005, time: 2024-09-28 08:06:48.188563\n","Batch 80, Disc Loss: 0.9938932061195374 , Gen Loss: 0.005611510947346687, time: 2024-09-28 08:07:11.890852\n","Batch 90, Disc Loss: 0.9915666580200195 , Gen Loss: 0.005601250100880861, time: 2024-09-28 08:07:35.717122\n","Epoch 28/50, time: 2024-09-28 08:08:01.395008\n","Batch 0, Disc Loss: 0.989162802696228 , Gen Loss: 0.005592252593487501, time: 2024-09-28 08:08:03.920696\n","Batch 10, Disc Loss: 0.9887498021125793 , Gen Loss: 0.005585724022239447, time: 2024-09-28 08:08:27.979525\n","Batch 20, Disc Loss: 0.9879102110862732 , Gen Loss: 0.005580549594014883, time: 2024-09-28 08:08:51.744710\n","Batch 30, Disc Loss: 0.9937400221824646 , Gen Loss: 0.005577852949500084, time: 2024-09-28 08:09:15.252005\n","Batch 40, Disc Loss: 0.9932405948638916 , Gen Loss: 0.005568148102611303, time: 2024-09-28 08:09:38.855737\n","Batch 50, Disc Loss: 0.9922414422035217 , Gen Loss: 0.005556326359510422, time: 2024-09-28 08:10:02.620598\n","Batch 60, Disc Loss: 0.9914066195487976 , Gen Loss: 0.0055444249883294106, time: 2024-09-28 08:10:26.363419\n","Batch 70, Disc Loss: 0.9907793998718262 , Gen Loss: 0.005532416515052319, time: 2024-09-28 08:10:49.933415\n","Batch 80, Disc Loss: 0.9895529747009277 , Gen Loss: 0.0055223992094397545, time: 2024-09-28 08:11:13.535153\n","Batch 90, Disc Loss: 0.9886559844017029 , Gen Loss: 0.005510806571692228, time: 2024-09-28 08:11:37.177944\n","Epoch 29/50, time: 2024-09-28 08:12:02.986905\n","Batch 0, Disc Loss: 0.988602876663208 , Gen Loss: 0.005500951316207647, time: 2024-09-28 08:12:05.534145\n","Batch 10, Disc Loss: 0.9882562160491943 , Gen Loss: 0.005490217357873917, time: 2024-09-28 08:12:29.659769\n","Batch 20, Disc Loss: 0.9852399230003357 , Gen Loss: 0.005484068300575018, time: 2024-09-28 08:12:53.230909\n","Batch 30, Disc Loss: 0.9828698039054871 , Gen Loss: 0.005476575810462236, time: 2024-09-28 08:13:17.033773\n","Batch 40, Disc Loss: 0.9821155071258545 , Gen Loss: 0.005466606002300978, time: 2024-09-28 08:13:40.569536\n","Batch 50, Disc Loss: 0.9822739958763123 , Gen Loss: 0.005456119310110807, time: 2024-09-28 08:14:04.188858\n","Batch 60, Disc Loss: 0.9823821187019348 , Gen Loss: 0.005448988173156977, time: 2024-09-28 08:14:27.950233\n","Batch 70, Disc Loss: 0.981544554233551 , Gen Loss: 0.005438605789095163, time: 2024-09-28 08:14:51.549592\n","Batch 80, Disc Loss: 0.980181872844696 , Gen Loss: 0.005428453907370567, time: 2024-09-28 08:15:15.315021\n","Batch 90, Disc Loss: 0.9790074825286865 , Gen Loss: 0.005418051965534687, time: 2024-09-28 08:15:38.905725\n","Epoch 30/50, time: 2024-09-28 08:16:04.728388\n","Batch 0, Disc Loss: 0.9781602025032043 , Gen Loss: 0.005408526863902807, time: 2024-09-28 08:16:07.271716\n","Batch 10, Disc Loss: 0.977374255657196 , Gen Loss: 0.005400107707828283, time: 2024-09-28 08:16:31.229614\n","Batch 20, Disc Loss: 0.9763591289520264 , Gen Loss: 0.005391421727836132, time: 2024-09-28 08:16:54.791516\n","Batch 30, Disc Loss: 0.9757510423660278 , Gen Loss: 0.0053835343569517136, time: 2024-09-28 08:17:18.536467\n","Batch 40, Disc Loss: 0.9755563139915466 , Gen Loss: 0.005374713335186243, time: 2024-09-28 08:17:42.121097\n","Batch 50, Disc Loss: 0.9750930070877075 , Gen Loss: 0.005365901626646519, time: 2024-09-28 08:18:05.683539\n","Batch 60, Disc Loss: 0.9743348956108093 , Gen Loss: 0.005357209127396345, time: 2024-09-28 08:18:29.236007\n","Batch 70, Disc Loss: 0.9738645553588867 , Gen Loss: 0.005347366910427809, time: 2024-09-28 08:18:52.941475\n","Batch 80, Disc Loss: 0.9719004034996033 , Gen Loss: 0.0053412774577736855, time: 2024-09-28 08:19:16.515518\n","Batch 90, Disc Loss: 0.9708617925643921 , Gen Loss: 0.00533773098140955, time: 2024-09-28 08:19:40.246598\n","Epoch 31/50, time: 2024-09-28 08:20:07.625807\n","Batch 0, Disc Loss: 0.9694206118583679 , Gen Loss: 0.00532919354736805, time: 2024-09-28 08:20:10.138714\n","Batch 10, Disc Loss: 0.9678568840026855 , Gen Loss: 0.005323923658579588, time: 2024-09-28 08:20:34.324970\n","Batch 20, Disc Loss: 0.9706275463104248 , Gen Loss: 0.005315854679793119, time: 2024-09-28 08:20:58.036295\n","Batch 30, Disc Loss: 0.9688534140586853 , Gen Loss: 0.00530709233134985, time: 2024-09-28 08:21:21.731811\n","Batch 40, Disc Loss: 0.9676507115364075 , Gen Loss: 0.005297856405377388, time: 2024-09-28 08:21:45.556870\n","Batch 50, Disc Loss: 0.9660115838050842 , Gen Loss: 0.00528990663588047, time: 2024-09-28 08:22:09.157918\n","Batch 60, Disc Loss: 0.9641185998916626 , Gen Loss: 0.0052831461653113365, time: 2024-09-28 08:22:32.758656\n","Batch 70, Disc Loss: 0.962226152420044 , Gen Loss: 0.005276804324239492, time: 2024-09-28 08:22:56.741930\n","Batch 80, Disc Loss: 0.96063631772995 , Gen Loss: 0.005269960500299931, time: 2024-09-28 08:23:20.419548\n","Batch 90, Disc Loss: 0.9590372443199158 , Gen Loss: 0.005265891086310148, time: 2024-09-28 08:23:44.122286\n","Epoch 32/50, time: 2024-09-28 08:24:09.763957\n","Batch 0, Disc Loss: 0.9578657746315002 , Gen Loss: 0.005260962527245283, time: 2024-09-28 08:24:12.516228\n","Batch 10, Disc Loss: 0.9565976858139038 , Gen Loss: 0.005256699398159981, time: 2024-09-28 08:24:36.576255\n","Batch 20, Disc Loss: 0.9551416635513306 , Gen Loss: 0.005252387840300798, time: 2024-09-28 08:25:00.308056\n","Batch 30, Disc Loss: 0.9549767374992371 , Gen Loss: 0.0052484082989394665, time: 2024-09-28 08:25:24.020656\n","Batch 40, Disc Loss: 0.953077495098114 , Gen Loss: 0.005242417100816965, time: 2024-09-28 08:25:47.807786\n","Batch 50, Disc Loss: 0.9512314796447754 , Gen Loss: 0.005236001685261726, time: 2024-09-28 08:26:11.488100\n","Batch 60, Disc Loss: 0.9514362215995789 , Gen Loss: 0.0052271680906414986, time: 2024-09-28 08:26:35.160832\n","Batch 70, Disc Loss: 0.9533484578132629 , Gen Loss: 0.005219378508627415, time: 2024-09-28 08:26:59.068911\n","Batch 80, Disc Loss: 0.9518781304359436 , Gen Loss: 0.005211907904595137, time: 2024-09-28 08:27:22.689918\n","Batch 90, Disc Loss: 0.950276255607605 , Gen Loss: 0.005206558853387833, time: 2024-09-28 08:27:46.374661\n","Epoch 33/50, time: 2024-09-28 08:28:11.935239\n","Batch 0, Disc Loss: 0.9480268955230713 , Gen Loss: 0.005201543681323528, time: 2024-09-28 08:28:14.469835\n","Batch 10, Disc Loss: 0.9461982250213623 , Gen Loss: 0.005195492412894964, time: 2024-09-28 08:28:39.430586\n","Batch 20, Disc Loss: 0.946018636226654 , Gen Loss: 0.005187085829675198, time: 2024-09-28 08:29:03.059323\n","Batch 30, Disc Loss: 0.9446712732315063 , Gen Loss: 0.005181066691875458, time: 2024-09-28 08:29:26.728084\n","Batch 40, Disc Loss: 0.9449332356452942 , Gen Loss: 0.005175091791898012, time: 2024-09-28 08:29:50.480436\n","Batch 50, Disc Loss: 0.9443533420562744 , Gen Loss: 0.005169077776372433, time: 2024-09-28 08:30:14.016993\n","Batch 60, Disc Loss: 0.9427613615989685 , Gen Loss: 0.005168634466826916, time: 2024-09-28 08:30:37.718515\n","Batch 70, Disc Loss: 0.9424101114273071 , Gen Loss: 0.005165122449398041, time: 2024-09-28 08:31:01.308114\n","Batch 80, Disc Loss: 0.9407952427864075 , Gen Loss: 0.005162169225513935, time: 2024-09-28 08:31:24.996775\n","Batch 90, Disc Loss: 0.9396259188652039 , Gen Loss: 0.005160389933735132, time: 2024-09-28 08:31:48.512901\n","Epoch 34/50, time: 2024-09-28 08:32:14.062546\n","Batch 0, Disc Loss: 0.941193699836731 , Gen Loss: 0.005158645566552877, time: 2024-09-28 08:32:16.602835\n","Batch 10, Disc Loss: 0.9387041926383972 , Gen Loss: 0.005156013648957014, time: 2024-09-28 08:32:41.189364\n","Batch 20, Disc Loss: 0.9364964365959167 , Gen Loss: 0.005150570068508387, time: 2024-09-28 08:33:05.005603\n","Batch 30, Disc Loss: 0.9353344440460205 , Gen Loss: 0.005149209871888161, time: 2024-09-28 08:33:28.705613\n","Batch 40, Disc Loss: 0.9365111589431763 , Gen Loss: 0.005141641944646835, time: 2024-09-28 08:33:52.396773\n","Batch 50, Disc Loss: 0.9353446364402771 , Gen Loss: 0.005133289843797684, time: 2024-09-28 08:34:16.384442\n","Batch 60, Disc Loss: 0.9349314570426941 , Gen Loss: 0.005124117247760296, time: 2024-09-28 08:34:40.139357\n","Batch 70, Disc Loss: 0.9341891407966614 , Gen Loss: 0.005117389839142561, time: 2024-09-28 08:35:03.929309\n","Batch 80, Disc Loss: 0.9333772659301758 , Gen Loss: 0.00511003565043211, time: 2024-09-28 08:35:27.963706\n","Batch 90, Disc Loss: 0.9331995844841003 , Gen Loss: 0.0051021333783864975, time: 2024-09-28 08:35:51.793658\n","Epoch 35/50, time: 2024-09-28 08:36:17.615644\n","Batch 0, Disc Loss: 0.9317779541015625 , Gen Loss: 0.005101165734231472, time: 2024-09-28 08:36:20.166137\n","Batch 10, Disc Loss: 0.9311515092849731 , Gen Loss: 0.005094476975500584, time: 2024-09-28 08:36:44.818710\n","Batch 20, Disc Loss: 0.9302069544792175 , Gen Loss: 0.0050880033522844315, time: 2024-09-28 08:37:08.774946\n","Batch 30, Disc Loss: 0.9278647899627686 , Gen Loss: 0.005087468773126602, time: 2024-09-28 08:37:32.581088\n","Batch 40, Disc Loss: 0.925578236579895 , Gen Loss: 0.005086260382086039, time: 2024-09-28 08:37:56.387909\n","Batch 50, Disc Loss: 0.928905189037323 , Gen Loss: 0.005089139100164175, time: 2024-09-28 08:38:20.401419\n","Batch 60, Disc Loss: 0.9291484951972961 , Gen Loss: 0.0050813606940209866, time: 2024-09-28 08:38:44.327941\n","Batch 70, Disc Loss: 0.9282016158103943 , Gen Loss: 0.005074187181890011, time: 2024-09-28 08:39:07.950393\n","Batch 80, Disc Loss: 0.9274911284446716 , Gen Loss: 0.005066016223281622, time: 2024-09-28 08:39:31.565711\n","Batch 90, Disc Loss: 0.9280338287353516 , Gen Loss: 0.005056452471762896, time: 2024-09-28 08:39:55.283274\n","Epoch 36/50, time: 2024-09-28 08:40:20.869253\n","Batch 0, Disc Loss: 0.9263044595718384 , Gen Loss: 0.005051185376942158, time: 2024-09-28 08:40:23.366281\n","Batch 10, Disc Loss: 0.9253934025764465 , Gen Loss: 0.005047767423093319, time: 2024-09-28 08:40:46.978765\n","Batch 20, Disc Loss: 0.9234008193016052 , Gen Loss: 0.005045071244239807, time: 2024-09-28 08:41:11.044604\n","Batch 30, Disc Loss: 0.9216669797897339 , Gen Loss: 0.005041464697569609, time: 2024-09-28 08:41:34.593138\n","Batch 40, Disc Loss: 0.9197731614112854 , Gen Loss: 0.005041441880166531, time: 2024-09-28 08:41:58.121746\n","Batch 50, Disc Loss: 0.9211940765380859 , Gen Loss: 0.005050504580140114, time: 2024-09-28 08:42:21.783613\n","Batch 60, Disc Loss: 0.9222163558006287 , Gen Loss: 0.0050417352467775345, time: 2024-09-28 08:42:45.425401\n","Batch 70, Disc Loss: 0.9241256713867188 , Gen Loss: 0.005032364744693041, time: 2024-09-28 08:43:09.012643\n","Batch 80, Disc Loss: 0.9237634539604187 , Gen Loss: 0.005023676436394453, time: 2024-09-28 08:43:32.641970\n","Batch 90, Disc Loss: 0.9247234463691711 , Gen Loss: 0.0050149597227573395, time: 2024-09-28 08:43:57.103840\n","Epoch 37/50, time: 2024-09-28 08:44:22.729503\n","Batch 0, Disc Loss: 0.9242566227912903 , Gen Loss: 0.005007825791835785, time: 2024-09-28 08:44:25.246520\n","Batch 10, Disc Loss: 0.9231085777282715 , Gen Loss: 0.005001491401344538, time: 2024-09-28 08:44:48.792431\n","Batch 20, Disc Loss: 0.9231583476066589 , Gen Loss: 0.004993170965462923, time: 2024-09-28 08:45:12.600341\n","Batch 30, Disc Loss: 0.9234724640846252 , Gen Loss: 0.004984481725841761, time: 2024-09-28 08:45:36.411794\n","Batch 40, Disc Loss: 0.9225850105285645 , Gen Loss: 0.00497750798240304, time: 2024-09-28 08:46:00.162593\n","Batch 50, Disc Loss: 0.9215552806854248 , Gen Loss: 0.004970488138496876, time: 2024-09-28 08:46:24.495416\n","Batch 60, Disc Loss: 0.9212450385093689 , Gen Loss: 0.0049649872817099094, time: 2024-09-28 08:46:48.387791\n","Batch 70, Disc Loss: 0.9204531311988831 , Gen Loss: 0.00495982775464654, time: 2024-09-28 08:47:12.099223\n","Batch 80, Disc Loss: 0.9205083847045898 , Gen Loss: 0.004952377639710903, time: 2024-09-28 08:47:35.788200\n","Batch 90, Disc Loss: 0.9198785424232483 , Gen Loss: 0.004947076551616192, time: 2024-09-28 08:47:59.670230\n","Epoch 38/50, time: 2024-09-28 08:48:25.525808\n","Batch 0, Disc Loss: 0.9183787107467651 , Gen Loss: 0.004944968037307262, time: 2024-09-28 08:48:28.236940\n","Batch 10, Disc Loss: 0.9174894094467163 , Gen Loss: 0.004940874874591827, time: 2024-09-28 08:48:53.712522\n","Batch 20, Disc Loss: 0.9187740087509155 , Gen Loss: 0.004936430137604475, time: 2024-09-28 08:49:17.441075\n","Batch 30, Disc Loss: 0.9176244139671326 , Gen Loss: 0.004933576099574566, time: 2024-09-28 08:49:41.223838\n","Batch 40, Disc Loss: 0.9174084663391113 , Gen Loss: 0.004928532987833023, time: 2024-09-28 08:50:04.776768\n","Batch 50, Disc Loss: 0.9177734851837158 , Gen Loss: 0.004922384861856699, time: 2024-09-28 08:50:28.412329\n","Batch 60, Disc Loss: 0.917448878288269 , Gen Loss: 0.004916256293654442, time: 2024-09-28 08:50:52.201650\n","Batch 70, Disc Loss: 0.9169442057609558 , Gen Loss: 0.004910360090434551, time: 2024-09-28 08:51:16.615605\n","Batch 80, Disc Loss: 0.9163464307785034 , Gen Loss: 0.0049039884470403194, time: 2024-09-28 08:51:40.188642\n","Batch 90, Disc Loss: 0.9149734973907471 , Gen Loss: 0.004899436142295599, time: 2024-09-28 08:52:03.701563\n","Epoch 39/50, time: 2024-09-28 08:52:29.624274\n","Batch 0, Disc Loss: 0.9150400757789612 , Gen Loss: 0.004893046338111162, time: 2024-09-28 08:52:32.174432\n","Batch 10, Disc Loss: 0.9144436717033386 , Gen Loss: 0.004889143630862236, time: 2024-09-28 08:52:55.901493\n","Batch 20, Disc Loss: 0.9130576848983765 , Gen Loss: 0.004884560126811266, time: 2024-09-28 08:53:19.633086\n","Batch 30, Disc Loss: 0.9113648533821106 , Gen Loss: 0.004881669767200947, time: 2024-09-28 08:53:44.130196\n","Batch 40, Disc Loss: 0.9093720316886902 , Gen Loss: 0.004890633746981621, time: 2024-09-28 08:54:07.816949\n","Batch 50, Disc Loss: 0.9081716537475586 , Gen Loss: 0.0049125212244689465, time: 2024-09-28 08:54:31.534639\n","Batch 60, Disc Loss: 0.906348466873169 , Gen Loss: 0.0049194153398275375, time: 2024-09-28 08:54:55.199076\n","Batch 70, Disc Loss: 0.9044462442398071 , Gen Loss: 0.0049300417304039, time: 2024-09-28 08:55:19.061161\n","Batch 80, Disc Loss: 0.9044076204299927 , Gen Loss: 0.0049445307813584805, time: 2024-09-28 08:55:42.669734\n","Batch 90, Disc Loss: 0.9039208889007568 , Gen Loss: 0.004943815991282463, time: 2024-09-28 08:56:06.456391\n","Epoch 40/50, time: 2024-09-28 08:56:28.491461\n","Batch 0, Disc Loss: 0.9030600786209106 , Gen Loss: 0.004938656929880381, time: 2024-09-28 08:56:30.984603\n","Batch 10, Disc Loss: 0.9034180641174316 , Gen Loss: 0.004932892508804798, time: 2024-09-28 08:56:54.604346\n","Batch 20, Disc Loss: 0.902540922164917 , Gen Loss: 0.004928064066916704, time: 2024-09-28 08:57:18.224683\n","Batch 30, Disc Loss: 0.9012544751167297 , Gen Loss: 0.0049257888458669186, time: 2024-09-28 08:57:41.934904\n","Batch 40, Disc Loss: 0.8995479345321655 , Gen Loss: 0.0049223750829696655, time: 2024-09-28 08:58:05.692539\n","Batch 50, Disc Loss: 0.8989465236663818 , Gen Loss: 0.0049194167368113995, time: 2024-09-28 08:58:29.254284\n","Batch 60, Disc Loss: 0.8996933102607727 , Gen Loss: 0.004923910368233919, time: 2024-09-28 08:58:53.175733\n","Batch 70, Disc Loss: 0.9023991823196411 , Gen Loss: 0.004924657754600048, time: 2024-09-28 08:59:16.850491\n","Batch 80, Disc Loss: 0.9021422266960144 , Gen Loss: 0.0049230488948524, time: 2024-09-28 08:59:40.270419\n","Batch 90, Disc Loss: 0.902013897895813 , Gen Loss: 0.004917512647807598, time: 2024-09-28 09:00:03.687747\n","Epoch 41/50, time: 2024-09-28 09:00:24.966030\n","Batch 0, Disc Loss: 0.9017619490623474 , Gen Loss: 0.004910503514111042, time: 2024-09-28 09:00:27.632687\n","Batch 10, Disc Loss: 0.9021050333976746 , Gen Loss: 0.004903886932879686, time: 2024-09-28 09:00:51.383176\n","Batch 20, Disc Loss: 0.9016724228858948 , Gen Loss: 0.004898953251540661, time: 2024-09-28 09:01:15.358047\n","Batch 30, Disc Loss: 0.901390790939331 , Gen Loss: 0.004893642384558916, time: 2024-09-28 09:01:40.680391\n","Batch 40, Disc Loss: 0.9013660550117493 , Gen Loss: 0.004887597635388374, time: 2024-09-28 09:02:04.439465\n","Batch 50, Disc Loss: 0.900393545627594 , Gen Loss: 0.004883259069174528, time: 2024-09-28 09:02:28.047349\n","Batch 60, Disc Loss: 0.8991950154304504 , Gen Loss: 0.004879290703684092, time: 2024-09-28 09:02:51.688405\n","Batch 70, Disc Loss: 0.8995590806007385 , Gen Loss: 0.004874843638390303, time: 2024-09-28 09:03:15.588017\n","Batch 80, Disc Loss: 0.8995433449745178 , Gen Loss: 0.0048685502260923386, time: 2024-09-28 09:03:39.371354\n","Batch 90, Disc Loss: 0.898824155330658 , Gen Loss: 0.004863697104156017, time: 2024-09-28 09:04:03.081900\n","Epoch 42/50, time: 2024-09-28 09:04:30.194562\n","Batch 0, Disc Loss: 0.8969454169273376 , Gen Loss: 0.00486098462715745, time: 2024-09-28 09:04:32.728269\n","Batch 10, Disc Loss: 0.8960906267166138 , Gen Loss: 0.004856535699218512, time: 2024-09-28 09:04:56.937324\n","Batch 20, Disc Loss: 0.8946925401687622 , Gen Loss: 0.004853495396673679, time: 2024-09-28 09:05:20.425996\n","Batch 30, Disc Loss: 0.894504964351654 , Gen Loss: 0.004849040415138006, time: 2024-09-28 09:05:43.990920\n","Batch 40, Disc Loss: 0.8937708735466003 , Gen Loss: 0.004846096504479647, time: 2024-09-28 09:06:07.749326\n","Batch 50, Disc Loss: 0.892461359500885 , Gen Loss: 0.0048446147702634335, time: 2024-09-28 09:06:31.426418\n","Batch 60, Disc Loss: 0.8914622068405151 , Gen Loss: 0.004843773785978556, time: 2024-09-28 09:06:55.029740\n","Batch 70, Disc Loss: 0.8904165029525757 , Gen Loss: 0.0048532793298363686, time: 2024-09-28 09:07:18.629861\n","Batch 80, Disc Loss: 0.8890016674995422 , Gen Loss: 0.004855703096836805, time: 2024-09-28 09:07:42.389564\n","Batch 90, Disc Loss: 0.8897172808647156 , Gen Loss: 0.0048533109948039055, time: 2024-09-28 09:08:05.908494\n","Epoch 43/50, time: 2024-09-28 09:08:31.720998\n","Batch 0, Disc Loss: 0.8899991512298584 , Gen Loss: 0.004848127719014883, time: 2024-09-28 09:08:34.239606\n","Batch 10, Disc Loss: 0.8896839618682861 , Gen Loss: 0.0048439460806548595, time: 2024-09-28 09:08:58.300245\n","Batch 20, Disc Loss: 0.8878296613693237 , Gen Loss: 0.004842627793550491, time: 2024-09-28 09:09:21.969294\n","Batch 30, Disc Loss: 0.8862218260765076 , Gen Loss: 0.004840466193854809, time: 2024-09-28 09:09:45.454140\n","Batch 40, Disc Loss: 0.8897014260292053 , Gen Loss: 0.004843880422413349, time: 2024-09-28 09:10:09.272567\n","Batch 50, Disc Loss: 0.8902248740196228 , Gen Loss: 0.004837601911276579, time: 2024-09-28 09:10:32.977214\n","Batch 60, Disc Loss: 0.889663577079773 , Gen Loss: 0.004832001868635416, time: 2024-09-28 09:10:56.354312\n","Batch 70, Disc Loss: 0.8896329402923584 , Gen Loss: 0.004825301002711058, time: 2024-09-28 09:11:19.709552\n","Batch 80, Disc Loss: 0.8893347978591919 , Gen Loss: 0.004819979425519705, time: 2024-09-28 09:11:43.383824\n","Batch 90, Disc Loss: 0.8882720470428467 , Gen Loss: 0.004815082997083664, time: 2024-09-28 09:12:07.005018\n","Epoch 44/50, time: 2024-09-28 09:12:32.553104\n","Batch 0, Disc Loss: 0.8866608738899231 , Gen Loss: 0.004812741186469793, time: 2024-09-28 09:12:35.073910\n","Batch 10, Disc Loss: 0.8846833109855652 , Gen Loss: 0.004813096486032009, time: 2024-09-28 09:12:59.368681\n","Batch 20, Disc Loss: 0.8826822638511658 , Gen Loss: 0.004815570544451475, time: 2024-09-28 09:13:23.092220\n","Batch 30, Disc Loss: 0.8808754682540894 , Gen Loss: 0.00481649162247777, time: 2024-09-28 09:13:46.679331\n","Batch 40, Disc Loss: 0.8789480924606323 , Gen Loss: 0.004817979875952005, time: 2024-09-28 09:14:10.285082\n","Batch 50, Disc Loss: 0.8770526647567749 , Gen Loss: 0.0048280879855155945, time: 2024-09-28 09:14:34.106220\n","Batch 60, Disc Loss: 0.8753082752227783 , Gen Loss: 0.004842632450163364, time: 2024-09-28 09:14:57.693388\n","Batch 70, Disc Loss: 0.8747729659080505 , Gen Loss: 0.004845910705626011, time: 2024-09-28 09:15:21.298507\n","Batch 80, Disc Loss: 0.8736599087715149 , Gen Loss: 0.004845734685659409, time: 2024-09-28 09:15:45.126266\n","Batch 90, Disc Loss: 0.8730977177619934 , Gen Loss: 0.004843902308493853, time: 2024-09-28 09:16:08.800103\n","Epoch 45/50, time: 2024-09-28 09:16:30.040034\n","Batch 0, Disc Loss: 0.8720723986625671 , Gen Loss: 0.004841214511543512, time: 2024-09-28 09:16:32.525976\n","Batch 10, Disc Loss: 0.8709263801574707 , Gen Loss: 0.004838142078369856, time: 2024-09-28 09:16:56.158430\n","Batch 20, Disc Loss: 0.8704681396484375 , Gen Loss: 0.004834707826375961, time: 2024-09-28 09:17:20.090960\n","Batch 30, Disc Loss: 0.8695265054702759 , Gen Loss: 0.004833919461816549, time: 2024-09-28 09:17:43.705392\n","Batch 40, Disc Loss: 0.8693777322769165 , Gen Loss: 0.0048311203718185425, time: 2024-09-28 09:18:07.378106\n","Batch 50, Disc Loss: 0.8690983653068542 , Gen Loss: 0.004826529882848263, time: 2024-09-28 09:18:31.248708\n","Batch 60, Disc Loss: 0.8679443001747131 , Gen Loss: 0.004823596682399511, time: 2024-09-28 09:18:54.914176\n","Batch 70, Disc Loss: 0.867112934589386 , Gen Loss: 0.004820303060114384, time: 2024-09-28 09:19:18.430472\n","Batch 80, Disc Loss: 0.8666092753410339 , Gen Loss: 0.004823433235287666, time: 2024-09-28 09:19:42.092094\n","Batch 90, Disc Loss: 0.8663209676742554 , Gen Loss: 0.004820896778255701, time: 2024-09-28 09:20:05.514904\n","Epoch 46/50, time: 2024-09-28 09:20:26.560091\n","Batch 0, Disc Loss: 0.8658473491668701 , Gen Loss: 0.00481551606208086, time: 2024-09-28 09:20:29.021312\n","Batch 10, Disc Loss: 0.8649783134460449 , Gen Loss: 0.0048117912374436855, time: 2024-09-28 09:20:52.445052\n","Batch 20, Disc Loss: 0.8644035458564758 , Gen Loss: 0.00480807526037097, time: 2024-09-28 09:21:16.118748\n","Batch 30, Disc Loss: 0.8630782961845398 , Gen Loss: 0.004808756988495588, time: 2024-09-28 09:21:39.446366\n","Batch 40, Disc Loss: 0.8626353144645691 , Gen Loss: 0.004806736949831247, time: 2024-09-28 09:22:02.843530\n","Batch 50, Disc Loss: 0.8619588017463684 , Gen Loss: 0.004804047290235758, time: 2024-09-28 09:22:26.601290\n","Batch 60, Disc Loss: 0.8623906970024109 , Gen Loss: 0.004800692666321993, time: 2024-09-28 09:22:50.103737\n","Batch 70, Disc Loss: 0.8623387813568115 , Gen Loss: 0.00479651615023613, time: 2024-09-28 09:23:13.639276\n","Batch 80, Disc Loss: 0.8616311550140381 , Gen Loss: 0.004793212749063969, time: 2024-09-28 09:23:37.130115\n","Batch 90, Disc Loss: 0.8621746897697449 , Gen Loss: 0.004789751023054123, time: 2024-09-28 09:24:00.812666\n","Epoch 47/50, time: 2024-09-28 09:24:26.374888\n","Batch 0, Disc Loss: 0.8625347018241882 , Gen Loss: 0.004785460419952869, time: 2024-09-28 09:24:28.906434\n","Batch 10, Disc Loss: 0.8624791502952576 , Gen Loss: 0.004781198222190142, time: 2024-09-28 09:24:53.236887\n","Batch 20, Disc Loss: 0.8629011511802673 , Gen Loss: 0.004778682254254818, time: 2024-09-28 09:25:17.112020\n","Batch 30, Disc Loss: 0.8621096014976501 , Gen Loss: 0.004778548143804073, time: 2024-09-28 09:25:40.873044\n","Batch 40, Disc Loss: 0.8615205883979797 , Gen Loss: 0.004778833594173193, time: 2024-09-28 09:26:04.508705\n","Batch 50, Disc Loss: 0.860878050327301 , Gen Loss: 0.004776687826961279, time: 2024-09-28 09:26:28.212926\n","Batch 60, Disc Loss: 0.8603647351264954 , Gen Loss: 0.00477670319378376, time: 2024-09-28 09:26:52.137320\n","Batch 70, Disc Loss: 0.8593993782997131 , Gen Loss: 0.004773623310029507, time: 2024-09-28 09:27:15.793614\n","Batch 80, Disc Loss: 0.8581303358078003 , Gen Loss: 0.004771358333528042, time: 2024-09-28 09:27:39.580041\n","Batch 90, Disc Loss: 0.857595682144165 , Gen Loss: 0.004772057756781578, time: 2024-09-28 09:28:03.455372\n","Epoch 48/50, time: 2024-09-28 09:28:29.125527\n","Batch 0, Disc Loss: 0.8596205711364746 , Gen Loss: 0.004768650513142347, time: 2024-09-28 09:28:31.652551\n","Batch 10, Disc Loss: 0.8587644696235657 , Gen Loss: 0.004764587618410587, time: 2024-09-28 09:28:55.773334\n","Batch 20, Disc Loss: 0.8584741353988647 , Gen Loss: 0.004759151488542557, time: 2024-09-28 09:29:19.420655\n","Batch 30, Disc Loss: 0.8594949245452881 , Gen Loss: 0.0047527761198580265, time: 2024-09-28 09:29:43.215689\n","Batch 40, Disc Loss: 0.8589397072792053 , Gen Loss: 0.00474791182205081, time: 2024-09-28 09:30:06.745432\n","Batch 50, Disc Loss: 0.8583626747131348 , Gen Loss: 0.004743929952383041, time: 2024-09-28 09:30:30.233601\n","Batch 60, Disc Loss: 0.8579958081245422 , Gen Loss: 0.004741300828754902, time: 2024-09-28 09:30:53.874007\n","Batch 70, Disc Loss: 0.8584854006767273 , Gen Loss: 0.004736046772450209, time: 2024-09-28 09:31:17.289936\n","Batch 80, Disc Loss: 0.8578901290893555 , Gen Loss: 0.004732649307698011, time: 2024-09-28 09:31:40.812399\n","Batch 90, Disc Loss: 0.8576825857162476 , Gen Loss: 0.004727852530777454, time: 2024-09-28 09:32:04.245105\n","Epoch 49/50, time: 2024-09-28 09:32:30.089862\n","Batch 0, Disc Loss: 0.8586004376411438 , Gen Loss: 0.0047224718146026134, time: 2024-09-28 09:32:32.649292\n","Batch 10, Disc Loss: 0.8585054874420166 , Gen Loss: 0.0047185770235955715, time: 2024-09-28 09:32:56.733471\n","Batch 20, Disc Loss: 0.8578360080718994 , Gen Loss: 0.0047156293876469135, time: 2024-09-28 09:33:20.325325\n","Batch 30, Disc Loss: 0.8607747554779053 , Gen Loss: 0.0047115241177380085, time: 2024-09-28 09:33:43.995932\n","Batch 40, Disc Loss: 0.8603066802024841 , Gen Loss: 0.004707305226475, time: 2024-09-28 09:34:07.575516\n","Batch 50, Disc Loss: 0.8597833514213562 , Gen Loss: 0.004703291226178408, time: 2024-09-28 09:34:31.176217\n","Batch 60, Disc Loss: 0.8602360486984253 , Gen Loss: 0.004699269309639931, time: 2024-09-28 09:34:54.690333\n","Batch 70, Disc Loss: 0.8590700626373291 , Gen Loss: 0.0046949186362326145, time: 2024-09-28 09:35:18.379997\n","Batch 80, Disc Loss: 0.8577240109443665 , Gen Loss: 0.0046933479607105255, time: 2024-09-28 09:35:42.071708\n","Batch 90, Disc Loss: 0.8561244606971741 , Gen Loss: 0.004693600814789534, time: 2024-09-28 09:36:05.775432\n","Epoch 50/50, time: 2024-09-28 09:36:31.652809\n","Batch 0, Disc Loss: 0.8545822501182556 , Gen Loss: 0.004694265313446522, time: 2024-09-28 09:36:34.174802\n","Batch 10, Disc Loss: 0.8534725904464722 , Gen Loss: 0.004694381728768349, time: 2024-09-28 09:36:58.522561\n","Batch 20, Disc Loss: 0.8520746827125549 , Gen Loss: 0.004697791300714016, time: 2024-09-28 09:37:22.273440\n","Batch 30, Disc Loss: 0.8533148765563965 , Gen Loss: 0.004704879596829414, time: 2024-09-28 09:37:45.969545\n","Batch 40, Disc Loss: 0.8527746796607971 , Gen Loss: 0.00470545282587409, time: 2024-09-28 09:38:09.775510\n","Batch 50, Disc Loss: 0.8530583381652832 , Gen Loss: 0.004701189696788788, time: 2024-09-28 09:38:33.532672\n","Batch 60, Disc Loss: 0.8524078726768494 , Gen Loss: 0.004698004107922316, time: 2024-09-28 09:38:57.192740\n","Batch 70, Disc Loss: 0.8519598245620728 , Gen Loss: 0.004694399423897266, time: 2024-09-28 09:39:20.992304\n","Batch 80, Disc Loss: 0.8510696291923523 , Gen Loss: 0.0046914187259972095, time: 2024-09-28 09:39:44.798310\n","Batch 90, Disc Loss: 0.8501763343811035 , Gen Loss: 0.004689755849540234, time: 2024-09-28 09:40:08.494977\n"]}],"source":["## training loop - without fit\n","import datetime\n","\n","latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n","if latest_checkpoint:\n","  srgan.load_weights(latest_checkpoint)\n","for epoch in range(epochs):\n","  print(f\"Epoch {epoch+1}/{epochs}, time: {datetime.datetime.now()}\")\n","  callbackList.on_epoch_begin(epoch)\n","  for batch,(lr_images,hr_images) in enumerate(train_dataset_srgan.take(100)):\n","    callbackList.on_batch_begin(batch)\n","    losses = srgan.train_step((lr_images,hr_images))\n","    callbackList.on_batch_end(batch,logs=losses)\n","    if batch%10==0:\n","      print(f\"Batch {batch}, Disc Loss: {losses['d_loss']} , Gen Loss: {losses['g_loss']}, time: {datetime.datetime.now()}\")\n","\n","  callbackList.on_epoch_end(epoch,logs=losses)\n","callbackList.on_train_end()"]},{"cell_type":"code","source":["image = cv2.imread(\"rose.jpg\")\n","image = image/255.0\n","image = tf.image.resize(image,(32,32))\n","#image = downscale_image(image)\n","image = tf.expand_dims(image,axis=0)\n","plt.imshow(image[0])"],"metadata":{"id":"xboEzGSXARAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image = generator.predict(image)\n","plt.imshow(image[0])"],"metadata":{"id":"VYjVkOXQBTpz"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}